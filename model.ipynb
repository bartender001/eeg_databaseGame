{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import scipy as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emotions.csv')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels to numerical values\n",
    "label_mapping = {'NEGATIVE' : 0, 'NEUTRAL' : 1, 'POSITIVE': 2}\n",
    "data['label'] = data['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, :-1] = scaler.fit_transform(data.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting in test train set\n",
    "X = data.drop('label', axis = 1)\n",
    "Y = data['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compiling\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "WARNING:tensorflow:From C:\\Users\\anura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\anura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "38/38 - 2s - loss: 1.0727 - accuracy: 0.7695 - val_loss: 0.5297 - val_accuracy: 0.9030 - 2s/epoch - 52ms/step\n",
      "Epoch 2/70\n",
      "38/38 - 0s - loss: 0.6976 - accuracy: 0.8650 - val_loss: 0.2504 - val_accuracy: 0.9398 - 330ms/epoch - 9ms/step\n",
      "Epoch 3/70\n",
      "38/38 - 0s - loss: 0.5958 - accuracy: 0.8843 - val_loss: 0.4668 - val_accuracy: 0.9197 - 348ms/epoch - 9ms/step\n",
      "Epoch 4/70\n",
      "38/38 - 0s - loss: 0.5335 - accuracy: 0.8944 - val_loss: 0.2395 - val_accuracy: 0.9431 - 304ms/epoch - 8ms/step\n",
      "Epoch 5/70\n",
      "38/38 - 0s - loss: 0.2909 - accuracy: 0.9061 - val_loss: 0.3027 - val_accuracy: 0.9231 - 327ms/epoch - 9ms/step\n",
      "Epoch 6/70\n",
      "38/38 - 0s - loss: 0.3281 - accuracy: 0.9028 - val_loss: 0.2397 - val_accuracy: 0.9298 - 319ms/epoch - 8ms/step\n",
      "Epoch 7/70\n",
      "38/38 - 0s - loss: 0.2314 - accuracy: 0.9329 - val_loss: 0.2673 - val_accuracy: 0.9197 - 318ms/epoch - 8ms/step\n",
      "Epoch 8/70\n",
      "38/38 - 0s - loss: 0.2309 - accuracy: 0.9296 - val_loss: 0.2444 - val_accuracy: 0.9298 - 320ms/epoch - 8ms/step\n",
      "Epoch 9/70\n",
      "38/38 - 0s - loss: 0.2066 - accuracy: 0.9355 - val_loss: 0.2461 - val_accuracy: 0.9498 - 400ms/epoch - 11ms/step\n",
      "Epoch 10/70\n",
      "38/38 - 0s - loss: 0.1869 - accuracy: 0.9371 - val_loss: 0.2184 - val_accuracy: 0.9465 - 297ms/epoch - 8ms/step\n",
      "Epoch 11/70\n",
      "38/38 - 0s - loss: 0.2010 - accuracy: 0.9220 - val_loss: 0.2093 - val_accuracy: 0.9331 - 338ms/epoch - 9ms/step\n",
      "Epoch 12/70\n",
      "38/38 - 0s - loss: 0.1567 - accuracy: 0.9447 - val_loss: 0.2134 - val_accuracy: 0.9465 - 351ms/epoch - 9ms/step\n",
      "Epoch 13/70\n",
      "38/38 - 0s - loss: 0.1284 - accuracy: 0.9505 - val_loss: 0.2341 - val_accuracy: 0.9465 - 346ms/epoch - 9ms/step\n",
      "Epoch 14/70\n",
      "38/38 - 0s - loss: 0.1212 - accuracy: 0.9606 - val_loss: 0.2151 - val_accuracy: 0.9498 - 315ms/epoch - 8ms/step\n",
      "Epoch 15/70\n",
      "38/38 - 0s - loss: 0.1330 - accuracy: 0.9581 - val_loss: 0.2935 - val_accuracy: 0.9365 - 296ms/epoch - 8ms/step\n",
      "Epoch 16/70\n",
      "38/38 - 0s - loss: 0.2045 - accuracy: 0.9573 - val_loss: 0.2463 - val_accuracy: 0.9398 - 341ms/epoch - 9ms/step\n",
      "Epoch 17/70\n",
      "38/38 - 0s - loss: 0.1853 - accuracy: 0.9522 - val_loss: 0.2582 - val_accuracy: 0.9565 - 300ms/epoch - 8ms/step\n",
      "Epoch 18/70\n",
      "38/38 - 0s - loss: 0.1863 - accuracy: 0.9497 - val_loss: 0.2700 - val_accuracy: 0.9532 - 299ms/epoch - 8ms/step\n",
      "Epoch 19/70\n",
      "38/38 - 0s - loss: 0.1424 - accuracy: 0.9598 - val_loss: 0.2219 - val_accuracy: 0.9398 - 330ms/epoch - 9ms/step\n",
      "Epoch 20/70\n",
      "38/38 - 0s - loss: 0.1230 - accuracy: 0.9606 - val_loss: 0.1803 - val_accuracy: 0.9498 - 345ms/epoch - 9ms/step\n",
      "Epoch 21/70\n",
      "38/38 - 0s - loss: 0.0700 - accuracy: 0.9732 - val_loss: 0.1749 - val_accuracy: 0.9632 - 320ms/epoch - 8ms/step\n",
      "Epoch 22/70\n",
      "38/38 - 0s - loss: 0.1402 - accuracy: 0.9648 - val_loss: 0.1642 - val_accuracy: 0.9666 - 308ms/epoch - 8ms/step\n",
      "Epoch 23/70\n",
      "38/38 - 0s - loss: 0.0829 - accuracy: 0.9698 - val_loss: 0.1874 - val_accuracy: 0.9666 - 311ms/epoch - 8ms/step\n",
      "Epoch 24/70\n",
      "38/38 - 0s - loss: 0.0755 - accuracy: 0.9740 - val_loss: 0.2450 - val_accuracy: 0.9532 - 303ms/epoch - 8ms/step\n",
      "Epoch 25/70\n",
      "38/38 - 0s - loss: 0.0573 - accuracy: 0.9807 - val_loss: 0.2599 - val_accuracy: 0.9498 - 298ms/epoch - 8ms/step\n",
      "Epoch 26/70\n",
      "38/38 - 0s - loss: 0.0544 - accuracy: 0.9832 - val_loss: 0.2748 - val_accuracy: 0.9498 - 339ms/epoch - 9ms/step\n",
      "Epoch 27/70\n",
      "38/38 - 0s - loss: 0.0636 - accuracy: 0.9799 - val_loss: 0.2210 - val_accuracy: 0.9599 - 340ms/epoch - 9ms/step\n",
      "Epoch 28/70\n",
      "38/38 - 0s - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.2569 - val_accuracy: 0.9599 - 325ms/epoch - 9ms/step\n",
      "Epoch 29/70\n",
      "38/38 - 0s - loss: 0.0813 - accuracy: 0.9824 - val_loss: 0.2085 - val_accuracy: 0.9699 - 329ms/epoch - 9ms/step\n",
      "Epoch 30/70\n",
      "38/38 - 0s - loss: 0.0607 - accuracy: 0.9841 - val_loss: 0.2489 - val_accuracy: 0.9699 - 292ms/epoch - 8ms/step\n",
      "Epoch 31/70\n",
      "38/38 - 0s - loss: 0.0256 - accuracy: 0.9883 - val_loss: 0.2133 - val_accuracy: 0.9732 - 296ms/epoch - 8ms/step\n",
      "Epoch 32/70\n",
      "38/38 - 0s - loss: 0.0722 - accuracy: 0.9774 - val_loss: 0.2277 - val_accuracy: 0.9732 - 291ms/epoch - 8ms/step\n",
      "Epoch 33/70\n",
      "38/38 - 0s - loss: 0.0449 - accuracy: 0.9824 - val_loss: 0.2846 - val_accuracy: 0.9565 - 298ms/epoch - 8ms/step\n",
      "Epoch 34/70\n",
      "38/38 - 0s - loss: 0.0719 - accuracy: 0.9790 - val_loss: 0.2970 - val_accuracy: 0.9599 - 311ms/epoch - 8ms/step\n",
      "Epoch 35/70\n",
      "38/38 - 0s - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.2274 - val_accuracy: 0.9666 - 288ms/epoch - 8ms/step\n",
      "Epoch 36/70\n",
      "38/38 - 0s - loss: 0.0591 - accuracy: 0.9832 - val_loss: 0.2898 - val_accuracy: 0.9666 - 304ms/epoch - 8ms/step\n",
      "Epoch 37/70\n",
      "38/38 - 0s - loss: 0.0416 - accuracy: 0.9858 - val_loss: 0.3157 - val_accuracy: 0.9632 - 334ms/epoch - 9ms/step\n",
      "Epoch 38/70\n",
      "38/38 - 0s - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.3315 - val_accuracy: 0.9498 - 315ms/epoch - 8ms/step\n",
      "Epoch 39/70\n",
      "38/38 - 0s - loss: 0.0367 - accuracy: 0.9941 - val_loss: 0.3329 - val_accuracy: 0.9632 - 311ms/epoch - 8ms/step\n",
      "Epoch 40/70\n",
      "38/38 - 0s - loss: 0.0324 - accuracy: 0.9941 - val_loss: 0.3167 - val_accuracy: 0.9666 - 294ms/epoch - 8ms/step\n",
      "Epoch 41/70\n",
      "38/38 - 0s - loss: 0.0289 - accuracy: 0.9883 - val_loss: 0.2730 - val_accuracy: 0.9699 - 342ms/epoch - 9ms/step\n",
      "Epoch 42/70\n",
      "38/38 - 0s - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.3583 - val_accuracy: 0.9632 - 286ms/epoch - 8ms/step\n",
      "Epoch 43/70\n",
      "38/38 - 0s - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.4551 - val_accuracy: 0.9666 - 338ms/epoch - 9ms/step\n",
      "Epoch 44/70\n",
      "38/38 - 0s - loss: 0.0287 - accuracy: 0.9891 - val_loss: 0.4141 - val_accuracy: 0.9833 - 319ms/epoch - 8ms/step\n",
      "Epoch 45/70\n",
      "38/38 - 0s - loss: 0.0475 - accuracy: 0.9874 - val_loss: 0.4264 - val_accuracy: 0.9799 - 338ms/epoch - 9ms/step\n",
      "Epoch 46/70\n",
      "38/38 - 0s - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.4360 - val_accuracy: 0.9732 - 312ms/epoch - 8ms/step\n",
      "Epoch 47/70\n",
      "38/38 - 0s - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.5369 - val_accuracy: 0.9599 - 298ms/epoch - 8ms/step\n",
      "Epoch 48/70\n",
      "38/38 - 0s - loss: 0.0387 - accuracy: 0.9883 - val_loss: 0.4102 - val_accuracy: 0.9666 - 309ms/epoch - 8ms/step\n",
      "Epoch 49/70\n",
      "38/38 - 0s - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.4223 - val_accuracy: 0.9732 - 320ms/epoch - 8ms/step\n",
      "Epoch 50/70\n",
      "38/38 - 0s - loss: 0.0647 - accuracy: 0.9832 - val_loss: 0.4925 - val_accuracy: 0.9498 - 291ms/epoch - 8ms/step\n",
      "Epoch 51/70\n",
      "38/38 - 1s - loss: 0.0602 - accuracy: 0.9832 - val_loss: 0.4440 - val_accuracy: 0.9666 - 505ms/epoch - 13ms/step\n",
      "Epoch 52/70\n",
      "38/38 - 0s - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.4739 - val_accuracy: 0.9732 - 337ms/epoch - 9ms/step\n",
      "Epoch 53/70\n",
      "38/38 - 0s - loss: 0.0251 - accuracy: 0.9899 - val_loss: 0.5052 - val_accuracy: 0.9732 - 325ms/epoch - 9ms/step\n",
      "Epoch 54/70\n",
      "38/38 - 0s - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.4757 - val_accuracy: 0.9833 - 331ms/epoch - 9ms/step\n",
      "Epoch 55/70\n",
      "38/38 - 0s - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.5713 - val_accuracy: 0.9632 - 290ms/epoch - 8ms/step\n",
      "Epoch 56/70\n",
      "38/38 - 0s - loss: 0.0181 - accuracy: 0.9925 - val_loss: 0.5428 - val_accuracy: 0.9732 - 307ms/epoch - 8ms/step\n",
      "Epoch 57/70\n",
      "38/38 - 0s - loss: 0.0268 - accuracy: 0.9925 - val_loss: 0.5552 - val_accuracy: 0.9732 - 300ms/epoch - 8ms/step\n",
      "Epoch 58/70\n",
      "38/38 - 1s - loss: 0.0455 - accuracy: 0.9874 - val_loss: 0.4517 - val_accuracy: 0.9632 - 521ms/epoch - 14ms/step\n",
      "Epoch 59/70\n",
      "38/38 - 0s - loss: 0.0715 - accuracy: 0.9832 - val_loss: 0.5310 - val_accuracy: 0.9632 - 293ms/epoch - 8ms/step\n",
      "Epoch 60/70\n",
      "38/38 - 0s - loss: 0.1109 - accuracy: 0.9749 - val_loss: 0.5666 - val_accuracy: 0.9465 - 302ms/epoch - 8ms/step\n",
      "Epoch 61/70\n",
      "38/38 - 0s - loss: 0.0916 - accuracy: 0.9832 - val_loss: 0.4292 - val_accuracy: 0.9565 - 339ms/epoch - 9ms/step\n",
      "Epoch 62/70\n",
      "38/38 - 0s - loss: 0.1083 - accuracy: 0.9690 - val_loss: 0.4341 - val_accuracy: 0.9398 - 294ms/epoch - 8ms/step\n",
      "Epoch 63/70\n",
      "38/38 - 0s - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.4146 - val_accuracy: 0.9565 - 300ms/epoch - 8ms/step\n",
      "Epoch 64/70\n",
      "38/38 - 0s - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.4076 - val_accuracy: 0.9666 - 300ms/epoch - 8ms/step\n",
      "Epoch 65/70\n",
      "38/38 - 0s - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.4383 - val_accuracy: 0.9599 - 280ms/epoch - 7ms/step\n",
      "Epoch 66/70\n",
      "38/38 - 0s - loss: 0.0232 - accuracy: 0.9908 - val_loss: 0.3849 - val_accuracy: 0.9632 - 288ms/epoch - 8ms/step\n",
      "Epoch 67/70\n",
      "38/38 - 0s - loss: 0.0269 - accuracy: 0.9899 - val_loss: 0.4108 - val_accuracy: 0.9532 - 303ms/epoch - 8ms/step\n",
      "Epoch 68/70\n",
      "38/38 - 0s - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.3616 - val_accuracy: 0.9666 - 284ms/epoch - 7ms/step\n",
      "Epoch 69/70\n",
      "38/38 - 0s - loss: 0.0346 - accuracy: 0.9883 - val_loss: 0.3536 - val_accuracy: 0.9599 - 290ms/epoch - 8ms/step\n",
      "Epoch 70/70\n",
      "38/38 - 0s - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.4383 - val_accuracy: 0.9632 - 280ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.2, epochs=70, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.5624988079071 %\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "model_acc = model.evaluate(x_test, y_test, verbose = 0)[1]\n",
    "print(f'{model_acc*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step\n",
      "[0 0 2 1 0 2 0 1 1 2 1 1 0 2 2 2 1 1 0 1 1 2 0 1 0 2 0 2 1 2 1 1 2 1 1 1 1\n",
      " 1 2 0 1 1 2 1 0 1 0 1 2 1 2 2 1 1 0 1 2 0 2 2 2 1 2 1 0 2 1 2 1 2 1 0 1 1\n",
      " 1 2 0 2 1 1 2 0 0 2 2 0 2 1 2 0 2 1 2 1 1 0 1 1 1 2 0 2 0 0 2 1 1 2 0 1 2\n",
      " 1 2 2 2 2 2 1 0 0 2 0 2 0 1 1 1 0 2 0 2 0 2 1 0 2 0 0 0 0 0 2 2 0 0 0 1 0\n",
      " 2 1 0 2 2 1 0 1 2 2 1 2 0 2 2 2 0 0 1 0 0 2 1 0 0 1 0 1 1 2 1 1 2 1 1 1 0\n",
      " 2 1 2 2 2 1 0 1 0 0 2 2 0 2 2 2 1 1 1 0 0 0 0 2 2 1 2 0 1 2 0 0 0 1 0 1 2\n",
      " 1 2 0 1 0 1 0 0 1 0 1 0 0 1 2 2 2 0 2 2 2 0 2 2 0 1 2 0 1 2 1 0 1 0 1 1 0\n",
      " 1 2 1 1 0 1 1 1 1 0 1 2 0 2 2 0 1 0 1 2 2 1 1 1 0 1 1 2 0 2 2 2 0 0 2 2 0\n",
      " 0 2 2 1 1 2 0 2 1 2 2 1 1 0 0 2 0 0 0 2 1 1 1 1 1 1 2 0 1 0 1 1 0 1 0 0 0\n",
      " 0 2 1 1 1 1 0 0 2 2 2 2 2 1 1 1 0 2 2 1 2 1 0 0 0 0 0 0 1 2 2 2 1 1 1 1 1\n",
      " 2 2 0 1 0 1 2 1 1 2 1 1 1 0 0 1 1 2 0 1 2 1 0 2 0 1 2 2 0 1 2 0 1 1 1 1 1\n",
      " 1 0 2 1 2 2 1 1 2 1 1 0 1 2 2 0 1 0 0 1 0 2 0 0 0 1 1 2 0 0 2 0 1 0 0 1 2\n",
      " 0 1 0 2 1 1 0 1 1 1 0 1 2 2 0 2 2 0 1 2 0 0 1 1 1 1 2 2 2 2 1 2 2 0 2 0 0\n",
      " 0 2 1 2 0 0 0 2 0 2 2 0 0 2 2 0 2 0 2 2 0 1 1 0 2 0 2 1 1 2 1 0 0 1 1 0 2\n",
      " 1 0 1 1 2 0 0 2 2 1 1 2 1 0 1 1 2 2 0 2 1 2 1 1 2 1 1 0 0 0 2 0 0 2 0 0 0\n",
      " 2 1 1 1 1 1 1 0 0 2 0 2 1 1 2 0 0 0 0 0 0 1 2 0 2 2 0 1 0 0 1 1 0 1 0 0 0\n",
      " 1 0 2 0 2 1 0 0 2 1 1 0 2 0 1 0 0 1 0 0 1 1 1 1 2 2 0 2 2 0 0 1 2 2 1 1 2\n",
      " 1 1 2 1 1 1 2 0 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#make pred\n",
    "y_pred = np.argmax(model.predict(x_test), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'my_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
